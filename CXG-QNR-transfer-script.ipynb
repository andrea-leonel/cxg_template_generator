{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9c6a86fe-5c10-44f7-a0f3-f433e6e5f7a1",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### 1) Extract the html code from the sat page in CXG Live:\n",
    "> With the S&T pop-up open, right-click 'Inspect' \n",
    "> Do ctrl+f  \n",
    "> Add skipsAndTriggersHistoryContainer in the search bar \n",
    "> Right-click the highlighted line\n",
    "> Copy > copy element > paste it in a notepad\n",
    "> Save it as html_{protoid}.html - replace protoid with the survey's protoid\n",
    "> On Jupyter's folder (the same folder where this script is saved), upload the html file. \n",
    "\n",
    "### 2) Extract DataList on CXG Connect:\n",
    "> Go Questionnaire Builder on the left handside menu\n",
    "> Serch your survey name and select it\n",
    "> Click Export S&T\n",
    "> In the excel file downloaded, there will be a tab called 'DataList', right-click it > Move or Copy\n",
    "> Under To book: click (new book) and save it as Datalist_{protoid} - replace protoid with the survey's protoid\n",
    "> On Jupyter's folder (the same folder where this script is saved), upload the html file. \n",
    "\n",
    "### 3) Add the protoids you'd like to process to the script.\n",
    "> Below there is a variable called protoid, add the protoids number there, always in this format ['protoid1','protoid2','protoid3',...,'protoid16']\n",
    "> with the cell below selected, press shift+Enter.\n",
    "> The templates will be saved in the same folder as the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463aba83-ac5b-445b-8874-23f31082cf16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved template files for: 29352\n",
      "Processed and saved template files for: 29364\n",
      "Processed and saved template files for: 29387\n",
      "Processed and saved template files for: 29401\n",
      "Processed and saved template files for: 29463\n",
      "Processed and saved template files for: 29245\n",
      "Processed and saved template files for: 29205\n",
      "Processed and saved template files for: 29229\n",
      "Processed and saved template files for: 29237\n",
      "Processed and saved template files for: 29249\n",
      "Processed and saved template files for: 29250\n",
      "Processed and saved template files for: 29251\n",
      "Processed and saved template files for: 29253\n",
      "Processed and saved template files for: 29261\n",
      "Processed and saved template files for: 29282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display\n",
    "from io import StringIO\n",
    "import csv\n",
    "import re\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill, Alignment, Font\n",
    "import traceback\n",
    "\n",
    "\n",
    "protoids = ['29352','29364','29387','29401','29463','29245','29205','29229','29237','29249','29250','29251','29253','29261','29282']\n",
    "\n",
    "def generate_sat_template(protoid):\n",
    " \n",
    "    try:\n",
    "        with open(f\"html_{protoid}.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "            trigger_history_container = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file does not exist!\")\n",
    "\n",
    "    soup = BeautifulSoup(trigger_history_container, 'html5lib')\n",
    "\n",
    "    box_main = soup.find_all('div', {'class': 'box-main'})\n",
    "    conditions = pd.DataFrame()\n",
    "    actions = pd.DataFrame()\n",
    "    group_n = []\n",
    "\n",
    "    sat_n = 0\n",
    "\n",
    "    for element in box_main:\n",
    "        if \"(Suspended)\" in str(element):\n",
    "            continue\n",
    "\n",
    "        sat_n += 1\n",
    "    \n",
    "        condition_table = element.find('table', id=lambda x: x and x.startswith('conditionDescriptionTable'))\n",
    "        block_exclude = element.find_all('div', {'class': 'historySectionLevelsDiv'})\n",
    "        block_text = []\n",
    "        tr = condition_table.find_all('tr')\n",
    "\n",
    "        for row in tr:\n",
    "        \n",
    "            condition_text = row.get_text(strip=True)\n",
    "            exclude_texts = [tag.get_text(strip=True) for tag in block_exclude if tag]\n",
    "\n",
    "            for text_exclude in exclude_texts:\n",
    "                if text_exclude in condition_text:\n",
    "                    condition_text = condition_text.replace(text_exclude, '')\n",
    "\n",
    "            input_tag = row.find('input', {'name': 'editremove'})\n",
    "            if input_tag:\n",
    "                value_attr = input_tag.get('value')\n",
    "                if value_attr:\n",
    "\n",
    "                    if '\"group\":' in value_attr:\n",
    "                        group_start = value_attr.find('\"group\":') + len('\"group\":')\n",
    "                        group_end = value_attr.find(',', group_start)\n",
    "                        group_n = value_attr[group_start:group_end].strip()\n",
    "                    else:\n",
    "                        group_n = None\n",
    "\n",
    "            block_text.append({'sat_n': sat_n, 'group_n': group_n, 'condition_text': condition_text})\n",
    "\n",
    "        df_condition = pd.DataFrame(block_text, columns=block_text[0])\n",
    "        conditions = pd.concat([conditions,df_condition],ignore_index=True)\n",
    "\n",
    "        action_table = element.find('table', id=lambda x: x and x.startswith('historyActionTable'))\n",
    "        if action_table:\n",
    "            rows = action_table.find_all('tr')\n",
    "            table_data = []\n",
    "            for row in rows:\n",
    "                cols = row.find_all(['th', 'td'])\n",
    "                cols_text = [col.get_text(strip=True) for col in cols]\n",
    "                table_data.append(cols_text)\n",
    "\n",
    "        df_action = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "        df_action['sat_n'] = sat_n\n",
    "        actions = pd.concat([actions,df_action],ignore_index=True)\n",
    "\n",
    "    sat = pd.merge(conditions, actions, on='sat_n', how='left')\n",
    "\n",
    "# Handling group numbering\n",
    "\n",
    "    sat['group_n'] = sat['group_n'].astype(int) + 1\n",
    "    sat['group_n'] = sat['group_n'].apply(lambda x: f\"Group {int(x)}\")\n",
    "\n",
    "    sat.loc[:,'group_n'] = sat.apply(lambda row: row['condition_text'] if 'Group' in str(row['condition_text']) else row['group_n'],axis=1)\n",
    "    sat.loc[:,'group_n'] = sat.apply(lambda row: str(row['group_n']).split(' ', 1)[1] if 'AND' in str(row['group_n']) or 'OR' in str(row['group_n']) else row['group_n'],axis=1)\n",
    "\n",
    "# Tidying up the table\n",
    "\n",
    "    new_column_names = {\n",
    "        'sat_n': 'sat_n',\n",
    "        'condition_text': 'cond_question',\n",
    "        'Action': 'act_action_question',\n",
    "        'Question': 'act_parameter',\n",
    "        'Answers': 'act_action_answer',\n",
    "        'Comment': 'act_action_comment'\n",
    "    }\n",
    "    sat = sat.rename(columns=new_column_names)\n",
    "    sat = sat[['sat_n','group_n','cond_question', 'act_parameter','act_action_answer', 'act_action_comment','act_action_question']]\n",
    "    \n",
    "# Breaking the tables into action and condition to be processed separately\n",
    "\n",
    "    conditions = sat[['sat_n','group_n','cond_question']]\n",
    "    actions = sat[['sat_n','act_parameter','act_action_answer', 'act_action_comment','act_action_question']]\n",
    "\n",
    "    conditions = conditions.drop_duplicates()\n",
    "    conditions.loc[:,'condition_n'] = conditions.groupby(['sat_n','group_n']).cumcount() + 1\n",
    "    conditions['condition_n'] = conditions['condition_n'].astype(str)  # Ensure string type\n",
    "    conditions.loc[:,'condition_n'] = 'Condition ' + conditions['condition_n'].astype(str)\n",
    "\n",
    "# Condition processing\n",
    "\n",
    "    conditions = conditions.copy()\n",
    "\n",
    "    conditions.loc[:,'cond_logical_operator'] = conditions['cond_question'].apply(lambda x: re.search(r'(AND|OR)', str(x)).group(0) if re.search(r'(AND|OR)', str(x)) else None)\n",
    "    conditions.loc[:,'cond_question_2'] = conditions.apply(lambda row: row['cond_question'].replace(row['cond_logical_operator'], '') if row['cond_logical_operator'] else row['cond_question'],axis=1)\n",
    "    conditions.loc[:,'cond_operator'] = conditions['cond_question_2'].apply(lambda x: re.search(r'(IS IN|IS NOT IN)', str(x)).group(0) if re.search(r'(IS IN|IS NOT IN)', str(x)) else None)\n",
    "    conditions.loc[:,'cond_parameter'] = conditions.apply(lambda row: (row['cond_question_2'].split(' [')[0] if isinstance(row['cond_question_2'], str) and ' [' in row['cond_question_2'] else (row['cond_question_2'].split(row['cond_operator'])[0].strip() if row['cond_operator'] and row['cond_operator'] in row['cond_question_2'] else None)),axis=1)\n",
    "    conditions['cond_parameter_value'] = conditions['cond_question_2'].apply(lambda x: re.search(r'IN\\s\\((.*?)\\)(?=[a-zA-Z]|$)', x).group(1) if isinstance(x, str) and re.search(r'IN\\s\\((.*?)\\)(?=[a-zA-Z]|$)', x) else None)\n",
    "    conditions.loc[:,'cond_parameter'] = conditions['cond_parameter'].apply(lambda x: x.split(' [')[0] if isinstance(x, str) and ' [' in x else x)\n",
    "\n",
    "    conditions.loc[:,'cond_parameter_type'] = 'Answer'\n",
    "\n",
    "    conditions['cond_type'] = 'Condition' \n",
    "\n",
    "    conditions.loc[conditions['cond_question'].str.contains('Group', case=False, na=False), 'cond_operator'] = conditions['cond_question'].apply(lambda x: re.search(r'(AND|OR)', str(x)).group(0) if re.search(r'(AND|OR)', str(x)) else \"\")\n",
    "    conditions.loc[conditions['cond_question'].str.contains('Group', case=False, na=False),['cond_parameter_type','cond_parameter', 'parameter_value']] = [\"\",\"\",\"\"]\n",
    "    conditions.loc[conditions['cond_question'].str.contains('Group', case=False, na=False), 'cond_type'] = \"Group\"\n",
    "    conditions.loc[~conditions['cond_question'].str.contains('Group', case=False, na=False), 'cond_parameter_type'] = \"Answer\"\n",
    "\n",
    "    conditions['cond_action'] = None\n",
    "    conditions['cond_action_option'] = None\n",
    "\n",
    "    conditions = conditions[['sat_n','group_n','condition_n','cond_type','cond_parameter_type','cond_parameter','cond_operator','cond_parameter_value','cond_action','cond_action_option','cond_logical_operator']]\n",
    "\n",
    "    answer_split = conditions['cond_parameter_value'].str.split(';', expand=True)\n",
    "    answer_split.columns = [f'cond_parameter_value_{i+1}' for i in range(answer_split.shape[1])]\n",
    "    conditions = pd.concat([conditions,answer_split], axis=1)\n",
    "\n",
    "    conditions_unpivot = pd.melt(conditions, id_vars=['sat_n','group_n','condition_n','cond_type','cond_parameter_type','cond_parameter','cond_operator','cond_action','cond_action_option','cond_logical_operator'], value_vars=answer_split.columns, var_name='answer', value_name='parameter_value')\n",
    "\n",
    "    conditions_final = conditions_unpivot.rename(columns={'parameter_value': 'cond_parameter_value'})\n",
    "    conditions_final = conditions_final[['sat_n','group_n','condition_n','cond_type','cond_parameter_type','cond_parameter','cond_operator','cond_parameter_value','cond_action','cond_action_option','cond_logical_operator']]\n",
    "    conditions_final = conditions_final.drop_duplicates()\n",
    "    conditions_final = conditions_final[~((conditions_final[['cond_parameter_value', 'cond_action', 'cond_action_option']].isna().all(axis=1)) & (conditions_final['cond_type'] != 'Group'))]\n",
    "    conditions_final = conditions_final.sort_values(by=['sat_n','group_n','condition_n','cond_type'], ascending=[True,True, True, False])\n",
    "\n",
    "# Action processing\n",
    "\n",
    "    actions = actions.copy()\n",
    "\n",
    "    actions.loc[:,'act_parameter'] = actions['act_parameter'].apply(lambda x: x.split(' [')[0])\n",
    "\n",
    "    actions.loc[:,'Parameter Type_1'] = actions['act_action_answer'].apply(lambda x: 'Answer' if x != \"\" else None)\n",
    "    actions.loc[:,'Parameter Type_2'] = actions['act_action_comment'].apply(lambda x: 'Comment' if x != \"\" else None)\n",
    "    actions.loc[:,'act_action_comment'] = actions['act_action_comment'].apply(lambda x: 'Change' if x == 'Set Comment(comment: )' else None)\n",
    "\n",
    "    action_split = actions['act_action_answer'].str.split(r'\\)(?=[a-zA-Z]|$)', expand=True)\n",
    "    action_split.columns = [f'act_action_answer_{i+1}' for i in range(action_split.shape[1])]\n",
    "    actions = pd.concat([actions, action_split], axis=1)\n",
    "\n",
    "    action_split2 = pd.DataFrame()\n",
    "    for i in range(action_split.shape[1]):\n",
    "        column_name = f'act_action_answer_{i+1}'\n",
    "        action_split2[[f'act_action_{i+1}', f'act_parameter_value_{i+1}']] = actions[column_name].apply(\n",
    "            lambda x: pd.Series(str(x).split('(', 1)) if isinstance(x, str) and '(' in str(x) else pd.Series([None, None]))\n",
    "    actions = actions[['sat_n','act_parameter', 'act_action_comment','act_action_question']]\n",
    "    actions = pd.concat([actions, action_split2], axis=1)\n",
    "\n",
    "    unpivoted_1 = pd.melt(actions, id_vars=['sat_n', 'act_parameter'], value_vars=['act_action_comment'], var_name='act_parameter_type', value_name='act_action')\n",
    "    unpivoted_1 = unpivoted_1[unpivoted_1['act_action'].notna()]\n",
    "    unpivoted_1.loc[:,\"act_parameter_type\"] = \"Comment\"\n",
    "\n",
    "    unpivoted_2 = pd.melt(actions, id_vars=['sat_n', 'act_parameter'], value_vars=['act_action_question'], var_name='act_parameter_type', value_name='act_action')\n",
    "    unpivoted_2 = unpivoted_2[unpivoted_2['act_action'].notna()]\n",
    "    unpivoted_2.loc[:,\"act_parameter_type\"] = \"Question\"\n",
    "\n",
    "    question_answer = pd.concat([unpivoted_1,unpivoted_2], ignore_index=True)\n",
    "    question_answer.loc[:,\"act_parameter_value\"] = None\n",
    "    question_answer = question_answer[['sat_n','act_parameter_type','act_parameter', \"act_parameter_value\",'act_action']]\n",
    "\n",
    "    question_answer = question_answer.drop_duplicates()\n",
    "\n",
    "    unpivoted_dfs = []\n",
    "    action_columns = [col for col in actions.columns if col.startswith('act_action_') and col.split('_')[-1].isdigit()]\n",
    "    for act_action in action_columns:\n",
    "        unpivoted_n = pd.melt(actions, id_vars=['sat_n', 'act_parameter'], value_vars=[act_action], var_name='act_parameter_type', value_name='value')\n",
    "        unpivoted_dfs.append(unpivoted_n)\n",
    "\n",
    "    action_unpivoted= pd.concat(unpivoted_dfs, ignore_index=True)\n",
    "    action_unpivoted = action_unpivoted[action_unpivoted['value'].notna()]\n",
    "    action_unpivoted.loc[:,'action_n'] = action_unpivoted['act_parameter_type'].apply(lambda x: x.split('_')[-1] if x.split('_')[-1].isdigit() else None)\n",
    "    action_unpivoted.loc[:,'act_parameter_type'] = action_unpivoted['act_parameter_type'].apply(lambda x: \"act_action\" if \"action\" in x else None)\n",
    "    action_unpivoted.loc[:,'id'] = action_unpivoted['sat_n'].astype(str) + action_unpivoted['act_parameter'].astype(str) + action_unpivoted['action_n'].astype(str)\n",
    "\n",
    "    unpivoted_dfs = []\n",
    "    param_columns = [col for col in actions.columns if col.startswith('act_parameter_value_')]\n",
    "    for act_param in param_columns:\n",
    "        unpivoted_n = pd.melt(actions, id_vars=['sat_n', 'act_parameter'], value_vars=[act_param], var_name='act_parameter_type', value_name='value')\n",
    "        unpivoted_dfs.append(unpivoted_n)\n",
    "\n",
    "    param_unpivoted= pd.concat(unpivoted_dfs, ignore_index=True)\n",
    "    param_unpivoted = param_unpivoted[param_unpivoted['value'].notna()]\n",
    "    param_unpivoted.loc[:,'action_n'] = param_unpivoted['act_parameter_type'].apply(lambda x: x.split('_')[-1] if x.split('_')[-1].isdigit() else None)\n",
    "    param_unpivoted.loc[:,'act_parameter_type'] = param_unpivoted['act_parameter_type'].apply(lambda x: \"act_parameter_value\" if \"parameter_value\" in x else None)\n",
    "    param_unpivoted.loc[:,'id'] = param_unpivoted['sat_n'].astype(str) + param_unpivoted['act_parameter'].astype(str) + param_unpivoted['action_n'].astype(str)\n",
    "\n",
    "    actions_param = pd.merge(action_unpivoted, param_unpivoted, how='left', on='id',suffixes=('_action', '_parameter'))\n",
    "\n",
    "    actions_param = actions_param.sort_values(by=['sat_n_action','act_parameter_action','action_n_action'], ascending=[True, True, True])\n",
    "    actions_param[\"act_parameter_type\"] = \"Answer\"\n",
    "    actions_param = actions_param[['sat_n_action','act_parameter_type','act_parameter_action','value_parameter','value_action','action_n_action']]\n",
    "\n",
    "    actions_param = actions_param.rename(columns={\n",
    "        'sat_n_action': 'sat_n',\n",
    "        'act_parameter_type': 'act_parameter_type',\n",
    "        'act_parameter_action': 'act_parameter',\n",
    "        'value_parameter': 'act_parameter_value',\n",
    "        'value_action': 'act_action',\n",
    "        'action_n_action': 'action_n'\n",
    "    })\n",
    "\n",
    "    actions_param = actions_param.drop_duplicates()\n",
    "\n",
    "    actions_final = pd.concat([question_answer, actions_param], ignore_index=True)\n",
    "\n",
    "    actions_final.loc[:,\"act_type\"] = \"Action\"\n",
    "    actions_final.loc[:,\"act_group_n\"] = None\n",
    "    actions_final.loc[:,\"act_condition_n\"] = None\n",
    "    actions_final.loc[:,\"act_operator\"] = None\n",
    "    actions_final.loc[:,\"act_action_option\"] = None\n",
    "    actions_final.loc[:,\"act_logical_operator\"] = None\n",
    "\n",
    "    actions_final = actions_final[['sat_n','act_group_n','act_condition_n','act_type','act_parameter_type','act_parameter','act_operator','act_parameter_value','act_action','act_action_option','act_logical_operator',]]\n",
    "    actions_final = actions_final.drop_duplicates()\n",
    "\n",
    "# Merging conditions and actions\n",
    "\n",
    "    conditions_final = conditions_final.rename(columns={\n",
    "        'sat_n': 'sat_n',\n",
    "        'cond_type': 'type',\n",
    "        'cond_parameter_type': 'parameter_type',\n",
    "        'cond_parameter': 'parameter',\n",
    "        'cond_operator': 'operator',\n",
    "        'cond_parameter_value': 'parameter_value',\n",
    "        'cond_action': 'action',\n",
    "        'cond_action_option': 'action_option',\n",
    "        'cond_logical_operator': 'logical_operator',\n",
    "    })\n",
    "\n",
    "    actions_final = actions_final.rename(columns={\n",
    "        'sat_n': 'sat_n',\n",
    "        'act_type': 'type',\n",
    "        'act_parameter_type': 'parameter_type',\n",
    "        'act_parameter': 'parameter',\n",
    "        'act_operator': 'operator',\n",
    "        'act_parameter_value': 'parameter_value',\n",
    "        'act_action' : 'action',\n",
    "        'act_action_option': 'action_option',\n",
    "        'act_logical_operator': 'logical_operator',\n",
    "    })\n",
    "\n",
    "    sat_combined = pd.concat([conditions_final, actions_final], ignore_index=True)#\n",
    "    sat_combined = sat_combined.sort_values(by=['sat_n','group_n','condition_n','type','parameter'], ascending=[True, True, True,False, True])\n",
    "\n",
    "# Equivalencies of operators and actions\n",
    "\n",
    "    sat_combined['operator'] = sat_combined['operator'].apply(lambda x: 'in' if x == 'IS IN' else '!in' if x == 'IS NOT IN' else None)\n",
    "\n",
    "    action_mapping = {\n",
    "        'show': 'Show',\n",
    "        'hide': 'Hide',\n",
    "        'Change': 'Change',\n",
    "        'Set Answer': 'Set',\n",
    "        'Clear Answer': 'Clear',\n",
    "        'Disable Answer': 'Disable',\n",
    "        'Enable Answer': 'Enable',\n",
    "        'Show Answer': 'Show',\n",
    "        'Hide Answer': 'Hide',\n",
    "    }\n",
    "    sat_combined['action'] = sat_combined['action'].apply(lambda x: action_mapping.get(x, None))\n",
    "\n",
    "# Formatting the final table to the template shape\n",
    "\n",
    "    def add_null_rows(group):\n",
    "        rule_row = {'sat_n': group['sat_n'].iloc[0], 'type': 'Rule'}\n",
    "        group_row = {'sat_n': group['sat_n'].iloc[0], 'type': 'Group'}\n",
    "        return pd.concat([pd.DataFrame([rule_row, group_row]), group])\n",
    "\n",
    "    sat_final = sat_combined.groupby('sat_n')[sat_combined.columns.tolist()].apply(add_null_rows).reset_index(drop=True)\n",
    "\n",
    "    sat_final.loc[:,'name'] = sat_final.apply(lambda row: sat_final.loc[row.name + 1, 'group_n'] if row['type'] == 'Group' and row.name + 1 < len(sat_final) else (row['condition_n'] if row['type'] == 'Condition' else None), axis=1)\n",
    "\n",
    "    sat_final = sat_final[['type','name','parameter_type','parameter','operator','parameter_value','action','action_option','logical_operator']]\n",
    "\n",
    "# Looking up question codes and replacing\n",
    "\n",
    "    datalist = pd.read_excel(f'datalist_{protoid}.xlsx', sheet_name='DataLists')\n",
    "\n",
    "    sat_final['parameter'] = sat_final['parameter'].apply(\n",
    "        lambda param: next(\n",
    "            (row for row in datalist.iloc[:, 0] if str(param) in str(row)),\n",
    "            param \n",
    "        )\n",
    "    )\n",
    "\n",
    "    sat_final = sat_final.rename(columns={\n",
    "            'name': 'Name',\n",
    "            'parameter_type': 'Parameter Type',\n",
    "            'parameter': 'Parameter',\n",
    "            'operator': 'Statement Operator',\n",
    "            'parameter_value': 'Parameter Value',\n",
    "            'action': 'Action',\n",
    "            'action_option': 'Action Option',\n",
    "            'logical_operator': 'Logical Operator'\n",
    "        })\n",
    "\n",
    "# Processing the Excel file\n",
    "\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    for col_idx, column in enumerate(sat_final.columns, start=1):\n",
    "        cell = ws.cell(row=1, column=col_idx, value=column) \n",
    "        cell.font = Font(bold=True)\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    sat_final = sat_final.reset_index(drop=True)\n",
    "\n",
    "    for row_idx, row in sat_final.iterrows():\n",
    "        for col_idx, value in enumerate(row, start=1):\n",
    "            cell = ws.cell(row=row_idx + 2, column=col_idx, value=value)\n",
    "            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    colors = {\n",
    "        'Rule': 'D88A55',\n",
    "        'Group': '00B09B',\n",
    "        'Condition': '9DD3C9',\n",
    "        'Action': 'D9D9D9'\n",
    "    }\n",
    "\n",
    "    for row_idx, row in sat_final.iterrows():\n",
    "        fill_color = colors.get(row['type'], None)\n",
    "        if fill_color:\n",
    "            for col_idx in range(1, len(sat_final.columns) + 1):\n",
    "                ws.cell(row=row_idx + 2, column=col_idx).fill = PatternFill(\n",
    "                    start_color=fill_color,\n",
    "                    end_color=fill_color,\n",
    "                    fill_type=\"solid\"\n",
    "                )\n",
    "\n",
    "    for column_cells in ws.columns:\n",
    "        ws.column_dimensions[column_cells[0].column_letter].width = 20\n",
    "\n",
    "    wb.save(f'template_{protoid}.xlsx')\n",
    "\n",
    "for protoid in protoids:\n",
    "    try:\n",
    "        generate_sat_template(protoid)\n",
    "        print(f\"Processed and saved template files for: {protoid}\")\n",
    "    except Exception as e:\n",
    "        tb = traceback.extract_tb(e.__traceback__)\n",
    "        line_number = tb[-1].lineno \n",
    "        print(f\"Error processing {protoid}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d6cb5-a5f5-4b2d-a1fd-7541cfe55b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f369fa-99a3-4282-a608-534d26193a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
